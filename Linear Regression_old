#With Vector
import numpy as np
import pandas as pd
def linearRegression_vector(X,Y,iter=1000,lr=0.01):
    x=np.array(X).T # Need x in (# of colums x # of rows)
    y=np.array(Y).T # Need y in row vector [y1,y2....ym]
    w=np.zeros((x.shape[0],1)) ## shape : [ # of columns in x , 1]
    b=0
    costf=[]
    for i in range(iter):
        Z=np.dot(w.T,x)+b ## computing b + w^t*x. 1 x m [ 1 X # of rows]
        E=Z-y ## Predicted - Actual [E1, E2.... Em] 1 * m
        m=x.shape[1] ## # of rows in vector x
        cost=(1/(2*m))* (np.sum(np.square(E))) ## cost function
        costf.append(cost)
        #((1/(2*len(Y)))*(error_1**2).sum(),10)
        ## We didn't use np.dot in above cost function because y and A are row cectors of size1 *m
        dw=(1/m)*np.dot(x,E.T) ## [number of columns x 1]
        db=(1/m)*np.sum(E) ## intercept
        w=w-lr*dw ## updated weights
        b=b-lr*db ## updated intercepts

    import matplotlib.pyplot as plt
    plt.plot(costf)
    return (w,b,cost)

# Without vector

import numpy as np
import pandas as pd
def linearRegression_GD(X,Y,iter=1000,lr=0.01):
    coef=[]
    result=[]
    X=pd.DataFrame(X)
    #for i in range(0,len(list(pd.DataFrame(X)))+1):
        #coef.append(0)
    coef=np.zeros(len(list(pd.DataFrame(X)))+1)
    for i in range(iter):
        counter=1
        hypo=0
        while counter <= len(coef):
            if counter-1 == 0:
                hypo = coef[counter-1]
            else:
                hypo=hypo+coef[counter-1]*X.iloc[:,counter-2]
            counter=counter+1
        
        error_1=(hypo-Y)
        counter=1
        der=[]
        newtheta=[]
        while counter <= len(coef):
            if counter-1 == 0:
                error=(error_1*1).sum()
            else:
                error=(error_1*list(X.iloc[:,counter-2])).sum()
            der.append(error)
            newtheta.append(round(coef[counter-1] - ((lr/len(Y))*error),5))
            counter=counter+1
        cost=round((1/(2*len(Y)))*(error_1**2).sum(),10)
        coef=newtheta[:]
        result.append([coef,cost])
        if len(result) >=2 and result[-1][1] > result[-2][1]:
            print("Check the learning rate.Gradient descent is increasing instead of decreasing")
            if len(result) == 2:
                print(result)
            else:
                print(result[-5:])
            break
        elif len(result) >=2 and result[-1][1] == result[-2][1]:
            break
    if len(result) >=2 and round(result[-1][1],5) < round(result[-2][1],5):
        print("We haven't reached the local minima yet. Try changing iterations or learning rate")
        
    return(result[-1])

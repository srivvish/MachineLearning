import numpy as np
import pandas as pd
def logisticRegression(X,Y,iter=1000,lr=0.01,cutoff=0.5,reg='N',lam=1.5):
    x=np.array(X).T # Need x in (# of colums x # of rows)
    y=np.array(Y).T # Need y in row vector [y1,y2....ym]
    w=np.zeros((x.shape[0],1)) ## shape : [ # of columns in x , 1]
    b=0
    m=x.shape[1] ## # of rows in vector x
    costf=[]
    #b=-5.58879715 
    #w=np.array([[-2.03169656], [3.36025375]])
    for i in range(iter):
        Z=np.dot(w.T,x)+b ## computing b + w^t*x. 1 x m [ 1 X # of rows]
        A=(1/(1+np.exp(-Z))) ## Activation function [A1, A2, A3...Am] 1 x m [ 1 X # of rows ]
        E=A-y ## Predicted - Actual [E1, E2.... Em] 1 * m
        if reg == 'Y':
            cost=(-1/m)* (np.sum(np.multiply(y,np.log(A))+np.multiply((1-y),np.log(1-A))))+(lam/(2*m)*(np.sum(np.square(w))))## cost function_regularization
            dw=(1/m)*np.dot(x,E.T) + (lam/m)*w
        else:
            cost=(-1/m)* (np.sum(np.multiply(y,np.log(A))+np.multiply((1-y),np.log(1-A))))
            dw=(1/m)*np.dot(x,E.T)
        ## We didn't use np.dot in above cost function because y and A are row cectors of size1 *m
        costf.append(cost)
         ## [number of columns x 1]## regularization
        db=(1/m)*np.sum(E) ## intercept
        w=w-lr*dw ## updated weights
        b=b-lr*db ## updated intercepts
    nZ=np.dot(w.T,x)+b
    nA=(1/(1+np.exp(-Z)))
    predict=np.where(nA>cutoff,1,0)
    unique, counts = np.unique(predict-y, return_counts=True)
    similar=dict(zip(unique, counts))[0]
    accuracy=(similar/m)*100
    import matplotlib.pyplot as plt
    plt.plot(costf)
    plt.xlabel('Number of Iterations')
    plt.ylabel('Cost Function')
    if reg == 'Y':
        plt.title('Plot of Cost Function with Regularization')
    else:
        plt.title('Plot of Cost Function')
    plt.show()
    return (cost,accuracy)
